# PRODIGY_INFOTECH_GenAI INTERNSHIP

TASK-1

Text Generation with GPT-2

Train a model to generate coherent and contextually relevant text based on a given prompt. Starting with GPT-2, a transformer model developed by OpenAI, you will learn how to fine-tune the model on a custom dataset to create text that mimics the style and structure of your training data. 

TASK-2

Image Generation with Pre-trained Models

tilize pre-trained generative models like DALL-E-mini or Stable Diffusion to create images from text prompts.

TASK-3

Text Generation with Markov Chains

Implement a simple text generation algorithm using Markov chains. This task involves creating a statistical model that predicts the probability of a character or word based on the previous one(s).
